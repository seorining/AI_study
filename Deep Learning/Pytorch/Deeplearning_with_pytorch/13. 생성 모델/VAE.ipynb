{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"../chap13/data\", train=True, transform=transform, download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"../chap13/data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=100, shuffle=True, num_workers=4, pin_memory=False)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = self.LeakyReLU(self.input1(x))\n",
    "        h_ = self.LeakyReLU(self.input2(h_))\n",
    "        mean = self.mean(h_)\n",
    "        log_var = self.var(h_)\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.LeakyReLU(self.hidden1(x))\n",
    "        h = self.LeakyReLU(self.hidden2(h))\n",
    "        x_hat = torch.sigmoid(self.output(h))\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)\n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n",
    "        x_hat = self.Decoder(z)\n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 784\n",
    "hidden_dim = 400\n",
    "latent_dim = 200\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim,\n",
    "                  latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim,\n",
    "                  hidden_dim=hidden_dim, output_dim=x_dim)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(\n",
    "        x_hat, x, reduction='sum')\n",
    "    KLD = - 0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return reproduction_loss, KLD\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_loc = 'scalar/'\n",
    "writer = SummaryWriter(saved_loc)\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "def train(epoch, model, train_loader, optimizer):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.view(batch_size, x_dim)\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        BCE, KLD = loss_function(x, x_hat, mean, log_var)\n",
    "        loss = BCE + KLD\n",
    "        writer.add_scalar(\"Train/Reconstruction Error\", BCE.item(),\n",
    "                          batch_idx + epoch * (len(train_loader.dataset)/batch_size))\n",
    "        writer.add_scalar(\"Train/KL-Divergence\", KLD.item(),\n",
    "                          batch_idx + epoch * (len(train_loader.dataset)/batch_size))\n",
    "        writer.add_scalar(\"Train/Total Loss\", loss.item(), batch_idx +\n",
    "                          epoch * (len(train_loader.dataset)/batch_size))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(x)))\n",
    "\n",
    "    print(\"======> Epoch: {} Average loss: {:.4f}\".format(\n",
    "        epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, _) in enumerate(test_loader):\n",
    "            x = x.view(batch_size, x_dim)\n",
    "            x = x.to(device)\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            BCE, KLD = loss_function(x, x_hat, mean, log_var)\n",
    "            loss = BCE + KLD\n",
    "\n",
    "            writer.add_scalar(\"Test/Reconstruction Error\", BCE.item(),\n",
    "                              batch_idx + epoch * (len(test_loader.dataset)/batch_size))\n",
    "            writer.add_scalar(\"Test/KL-Divergence\", KLD.item(),\n",
    "                              batch_idx + epoch * (len(test_loader.dataset)/batch_size))\n",
    "            writer.add_scalar(\"Test/Total Loss\", loss.item(), batch_idx +\n",
    "                              epoch * (len(test_loader.dataset)/batch_size))\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                n = min(x.size(0), 8)\n",
    "                comparison = torch.cat(\n",
    "                    [x[:n], x_hat.view(batch_size, x_dim)[:n]])\n",
    "                grid = torchvision.utils.make_grid(comparison.cpu())\n",
    "                writer.add_image(\n",
    "                    \"Test image - Above: Real data, below: reconstruction data\", grid, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\t Loss: 545.139258\n",
      "Train Epoch: 0 [10000/60000 (17%)]\t Loss: 198.182793\n",
      "Train Epoch: 0 [20000/60000 (33%)]\t Loss: 180.591875\n",
      "Train Epoch: 0 [30000/60000 (50%)]\t Loss: 168.394277\n",
      "Train Epoch: 0 [40000/60000 (67%)]\t Loss: 150.181865\n",
      "Train Epoch: 0 [50000/60000 (83%)]\t Loss: 148.615000\n",
      "======> Epoch: 0 Average loss: 173.7764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:01<00:32,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\t Loss: 146.846182\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t Loss: 134.781787\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t Loss: 123.950195\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t Loss: 127.748301\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t Loss: 129.141113\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t Loss: 122.684102\n",
      "======> Epoch: 1 Average loss: 128.6877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:02<00:30,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Loss: 119.847539\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t Loss: 120.912012\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t Loss: 119.611475\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t Loss: 114.317959\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t Loss: 118.211973\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t Loss: 111.680605\n",
      "======> Epoch: 2 Average loss: 116.5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:03<00:28,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Loss: 116.001318\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t Loss: 117.705576\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t Loss: 112.246543\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t Loss: 113.769082\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t Loss: 111.878145\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t Loss: 104.939336\n",
      "======> Epoch: 3 Average loss: 112.3941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:04<00:27,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\t Loss: 108.650098\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t Loss: 111.457734\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t Loss: 108.007900\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t Loss: 111.883516\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t Loss: 111.024424\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t Loss: 108.845879\n",
      "======> Epoch: 4 Average loss: 109.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:05<00:26,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\t Loss: 108.198203\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t Loss: 109.781055\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t Loss: 104.357520\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t Loss: 112.536348\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t Loss: 108.912441\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t Loss: 109.681016\n",
      "======> Epoch: 5 Average loss: 108.4641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:06<00:25,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\t Loss: 109.819258\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t Loss: 107.536709\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t Loss: 105.248359\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t Loss: 102.188584\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t Loss: 105.343252\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t Loss: 107.447012\n",
      "======> Epoch: 6 Average loss: 107.2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:07<00:24,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\t Loss: 108.913535\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t Loss: 107.704648\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t Loss: 102.599883\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t Loss: 107.019238\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t Loss: 107.393584\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t Loss: 107.295498\n",
      "======> Epoch: 7 Average loss: 106.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:08<00:23,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\t Loss: 103.713594\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t Loss: 104.332754\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t Loss: 104.885332\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t Loss: 106.099980\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t Loss: 101.704717\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t Loss: 100.471504\n",
      "======> Epoch: 8 Average loss: 105.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:09<00:22,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\t Loss: 105.743945\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t Loss: 108.836240\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t Loss: 105.108252\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t Loss: 101.845957\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t Loss: 101.812041\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t Loss: 103.572148\n",
      "======> Epoch: 9 Average loss: 104.7480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:10<00:20,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\t Loss: 103.411914\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t Loss: 102.013516\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t Loss: 101.862285\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t Loss: 102.406367\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t Loss: 105.705156\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t Loss: 101.219902\n",
      "======> Epoch: 10 Average loss: 104.2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:11<00:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\t Loss: 102.798154\n",
      "Train Epoch: 11 [10000/60000 (17%)]\t Loss: 103.389551\n",
      "Train Epoch: 11 [20000/60000 (33%)]\t Loss: 106.058799\n",
      "Train Epoch: 11 [30000/60000 (50%)]\t Loss: 98.317256\n",
      "Train Epoch: 11 [40000/60000 (67%)]\t Loss: 102.457803\n",
      "Train Epoch: 11 [50000/60000 (83%)]\t Loss: 104.038613\n",
      "======> Epoch: 11 Average loss: 103.7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:12<00:18,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\t Loss: 104.321738\n",
      "Train Epoch: 12 [10000/60000 (17%)]\t Loss: 107.781758\n",
      "Train Epoch: 12 [20000/60000 (33%)]\t Loss: 101.854824\n",
      "Train Epoch: 12 [30000/60000 (50%)]\t Loss: 101.526641\n",
      "Train Epoch: 12 [40000/60000 (67%)]\t Loss: 102.231230\n",
      "Train Epoch: 12 [50000/60000 (83%)]\t Loss: 102.349570\n",
      "======> Epoch: 12 Average loss: 103.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:13<00:17,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\t Loss: 100.732676\n",
      "Train Epoch: 13 [10000/60000 (17%)]\t Loss: 103.239453\n",
      "Train Epoch: 13 [20000/60000 (33%)]\t Loss: 104.925039\n",
      "Train Epoch: 13 [30000/60000 (50%)]\t Loss: 101.364824\n",
      "Train Epoch: 13 [40000/60000 (67%)]\t Loss: 104.626230\n",
      "Train Epoch: 13 [50000/60000 (83%)]\t Loss: 106.665625\n",
      "======> Epoch: 13 Average loss: 102.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:14<00:17,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\t Loss: 106.596563\n",
      "Train Epoch: 14 [10000/60000 (17%)]\t Loss: 104.291367\n",
      "Train Epoch: 14 [20000/60000 (33%)]\t Loss: 100.351895\n",
      "Train Epoch: 14 [30000/60000 (50%)]\t Loss: 98.539521\n",
      "Train Epoch: 14 [40000/60000 (67%)]\t Loss: 102.473945\n",
      "Train Epoch: 14 [50000/60000 (83%)]\t Loss: 103.522441\n",
      "======> Epoch: 14 Average loss: 102.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:15<00:15,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\t Loss: 98.729189\n",
      "Train Epoch: 15 [10000/60000 (17%)]\t Loss: 100.249883\n",
      "Train Epoch: 15 [20000/60000 (33%)]\t Loss: 101.777852\n",
      "Train Epoch: 15 [30000/60000 (50%)]\t Loss: 99.736035\n",
      "Train Epoch: 15 [40000/60000 (67%)]\t Loss: 102.721084\n",
      "Train Epoch: 15 [50000/60000 (83%)]\t Loss: 99.768125\n",
      "======> Epoch: 15 Average loss: 102.2215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:16<00:14,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\t Loss: 98.812607\n",
      "Train Epoch: 16 [10000/60000 (17%)]\t Loss: 103.078828\n",
      "Train Epoch: 16 [20000/60000 (33%)]\t Loss: 101.481719\n",
      "Train Epoch: 16 [30000/60000 (50%)]\t Loss: 102.262158\n",
      "Train Epoch: 16 [40000/60000 (67%)]\t Loss: 102.836270\n",
      "Train Epoch: 16 [50000/60000 (83%)]\t Loss: 104.735840\n",
      "======> Epoch: 16 Average loss: 102.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:17<00:13,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\t Loss: 100.197471\n",
      "Train Epoch: 17 [10000/60000 (17%)]\t Loss: 100.993809\n",
      "Train Epoch: 17 [20000/60000 (33%)]\t Loss: 99.718369\n",
      "Train Epoch: 17 [30000/60000 (50%)]\t Loss: 102.858789\n",
      "Train Epoch: 17 [40000/60000 (67%)]\t Loss: 100.042266\n",
      "Train Epoch: 17 [50000/60000 (83%)]\t Loss: 97.606641\n",
      "======> Epoch: 17 Average loss: 101.8172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:18<00:12,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\t Loss: 105.652842\n",
      "Train Epoch: 18 [10000/60000 (17%)]\t Loss: 102.902871\n",
      "Train Epoch: 18 [20000/60000 (33%)]\t Loss: 105.447695\n",
      "Train Epoch: 18 [30000/60000 (50%)]\t Loss: 103.061367\n",
      "Train Epoch: 18 [40000/60000 (67%)]\t Loss: 101.421064\n",
      "Train Epoch: 18 [50000/60000 (83%)]\t Loss: 103.434414\n",
      "======> Epoch: 18 Average loss: 101.6480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:20<00:11,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\t Loss: 105.224297\n",
      "Train Epoch: 19 [10000/60000 (17%)]\t Loss: 95.669658\n",
      "Train Epoch: 19 [20000/60000 (33%)]\t Loss: 103.547871\n",
      "Train Epoch: 19 [30000/60000 (50%)]\t Loss: 107.128896\n",
      "Train Epoch: 19 [40000/60000 (67%)]\t Loss: 105.863418\n",
      "Train Epoch: 19 [50000/60000 (83%)]\t Loss: 101.896406\n",
      "======> Epoch: 19 Average loss: 101.4236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:21<00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\t Loss: 101.371641\n",
      "Train Epoch: 20 [10000/60000 (17%)]\t Loss: 101.284873\n",
      "Train Epoch: 20 [20000/60000 (33%)]\t Loss: 98.742500\n",
      "Train Epoch: 20 [30000/60000 (50%)]\t Loss: 103.330078\n",
      "Train Epoch: 20 [40000/60000 (67%)]\t Loss: 101.689844\n",
      "Train Epoch: 20 [50000/60000 (83%)]\t Loss: 100.631641\n",
      "======> Epoch: 20 Average loss: 101.2427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:22<00:09,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\t Loss: 101.533994\n",
      "Train Epoch: 21 [10000/60000 (17%)]\t Loss: 102.167715\n",
      "Train Epoch: 21 [20000/60000 (33%)]\t Loss: 98.689160\n",
      "Train Epoch: 21 [30000/60000 (50%)]\t Loss: 102.020811\n",
      "Train Epoch: 21 [40000/60000 (67%)]\t Loss: 101.895742\n",
      "Train Epoch: 21 [50000/60000 (83%)]\t Loss: 101.241699\n",
      "======> Epoch: 21 Average loss: 101.1577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:23<00:08,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\t Loss: 98.782285\n",
      "Train Epoch: 22 [10000/60000 (17%)]\t Loss: 99.530596\n",
      "Train Epoch: 22 [20000/60000 (33%)]\t Loss: 94.709346\n",
      "Train Epoch: 22 [30000/60000 (50%)]\t Loss: 100.933779\n",
      "Train Epoch: 22 [40000/60000 (67%)]\t Loss: 105.162383\n",
      "Train Epoch: 22 [50000/60000 (83%)]\t Loss: 102.188477\n",
      "======> Epoch: 22 Average loss: 100.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:24<00:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\t Loss: 99.757383\n",
      "Train Epoch: 23 [10000/60000 (17%)]\t Loss: 100.429658\n",
      "Train Epoch: 23 [20000/60000 (33%)]\t Loss: 98.562012\n",
      "Train Epoch: 23 [30000/60000 (50%)]\t Loss: 96.646602\n",
      "Train Epoch: 23 [40000/60000 (67%)]\t Loss: 104.696543\n",
      "Train Epoch: 23 [50000/60000 (83%)]\t Loss: 103.985254\n",
      "======> Epoch: 23 Average loss: 100.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:25<00:06,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\t Loss: 98.671387\n",
      "Train Epoch: 24 [10000/60000 (17%)]\t Loss: 97.861016\n",
      "Train Epoch: 24 [20000/60000 (33%)]\t Loss: 101.260469\n",
      "Train Epoch: 24 [30000/60000 (50%)]\t Loss: 99.668018\n",
      "Train Epoch: 24 [40000/60000 (67%)]\t Loss: 103.398779\n",
      "Train Epoch: 24 [50000/60000 (83%)]\t Loss: 97.303945\n",
      "======> Epoch: 24 Average loss: 100.7020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:26<00:05,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\t Loss: 100.549277\n",
      "Train Epoch: 25 [10000/60000 (17%)]\t Loss: 101.550928\n",
      "Train Epoch: 25 [20000/60000 (33%)]\t Loss: 100.953271\n",
      "Train Epoch: 25 [30000/60000 (50%)]\t Loss: 106.390234\n",
      "Train Epoch: 25 [40000/60000 (67%)]\t Loss: 99.301211\n",
      "Train Epoch: 25 [50000/60000 (83%)]\t Loss: 100.892676\n",
      "======> Epoch: 25 Average loss: 100.6037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:27<00:04,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\t Loss: 97.813750\n",
      "Train Epoch: 26 [10000/60000 (17%)]\t Loss: 100.888350\n",
      "Train Epoch: 26 [20000/60000 (33%)]\t Loss: 101.917715\n",
      "Train Epoch: 26 [30000/60000 (50%)]\t Loss: 102.056777\n",
      "Train Epoch: 26 [40000/60000 (67%)]\t Loss: 97.317285\n",
      "Train Epoch: 26 [50000/60000 (83%)]\t Loss: 100.518535\n",
      "======> Epoch: 26 Average loss: 100.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:28<00:03,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\t Loss: 100.471445\n",
      "Train Epoch: 27 [10000/60000 (17%)]\t Loss: 100.295635\n",
      "Train Epoch: 27 [20000/60000 (33%)]\t Loss: 96.985088\n",
      "Train Epoch: 27 [30000/60000 (50%)]\t Loss: 99.973779\n",
      "Train Epoch: 27 [40000/60000 (67%)]\t Loss: 100.326484\n",
      "Train Epoch: 27 [50000/60000 (83%)]\t Loss: 108.091016\n",
      "======> Epoch: 27 Average loss: 100.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:29<00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\t Loss: 96.874551\n",
      "Train Epoch: 28 [10000/60000 (17%)]\t Loss: 101.833477\n",
      "Train Epoch: 28 [20000/60000 (33%)]\t Loss: 95.250479\n",
      "Train Epoch: 28 [30000/60000 (50%)]\t Loss: 99.681719\n",
      "Train Epoch: 28 [40000/60000 (67%)]\t Loss: 100.682402\n",
      "Train Epoch: 28 [50000/60000 (83%)]\t Loss: 98.413037\n",
      "======> Epoch: 28 Average loss: 100.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [00:30<00:01,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\t Loss: 101.295098\n",
      "Train Epoch: 29 [10000/60000 (17%)]\t Loss: 102.861465\n",
      "Train Epoch: 29 [20000/60000 (33%)]\t Loss: 97.502266\n",
      "Train Epoch: 29 [30000/60000 (50%)]\t Loss: 101.330381\n",
      "Train Epoch: 29 [40000/60000 (67%)]\t Loss: 97.677188\n",
      "Train Epoch: 29 [50000/60000 (83%)]\t Loss: 101.826963\n",
      "======> Epoch: 29 Average loss: 100.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:31<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for epoch in tqdm(range(0, epochs)):\n",
    "    train(epoch, model, train_loader, optimizer)\n",
    "    test(epoch, model, test_loader)\n",
    "    print(\"\\n\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "E1010 02:03:54.039050 139957028296512 program.py:300] TensorBoard could not bind to port 9000, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 9000, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir scalar --port=9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
